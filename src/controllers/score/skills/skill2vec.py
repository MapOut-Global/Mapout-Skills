# -*- coding: utf-8 -*-
"""skill2vec_implementation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-svpBfi4WgTu0affOQMIBbXD4kCv_WcM
"""
import pandas as pd
import numpy as np
from nltk.corpus import stopwords
from gensim.models import word2vec
import nltk.data
import re
import logging
from scipy import spatial
import gensim
import sys

model1 = gensim.models.KeyedVectors.load_word2vec_format("./src/controllers/score/skills/skill2vec.bin", binary=True)


def avg_feature_vector(words, model1, num_features):
    # function to average all words vectors in a given paragraph
    featureVec = np.zeros((num_features,), dtype="float32")
    nwords = 0

    # list containing names of words in the vocabulary
    # index2word_set = set(model1.index2word)  # this is moved as input param for performance reasons
    index2word_set = set(model1.index_to_key)  # this is moved as input param for performance reasons
    for word in words:
        if word in index2word_set:
            nwords = nwords + 1
            featureVec = np.add(featureVec, model1[word])

    if nwords > 0:
        featureVec = np.divide(featureVec, nwords)
    return featureVec


def sum_feature_vector(words, model1, num_features):
    # function to average all words vectors in a given paragraph
    featureVec = np.zeros((num_features,), dtype="float32")
    nwords = 0

    # list containing names of words in the vocabulary
    index2word_set = set(model1.index2word)  # this is moved as input param for performance reasons
    for word in words:
        if word in index2word_set:
            nwords = nwords + 1
            featureVec = np.add(featureVec, model1[word])

    #         if(nwords>0):
    #             featureVec = np.divide(featureVec, nwords)
    return featureVec


def compare_two_list_skills(skills_1, skills_2):
    sentence_1_avg_vector = avg_feature_vector(skills_1.split(), model1=model1, num_features=300)
    sentence_2_avg_vector = avg_feature_vector(skills_2.split(), model1=model1, num_features=300)
    sen1_sen2_similarity = 1 - spatial.distance.cosine(sentence_1_avg_vector, sentence_2_avg_vector)

    # print ('Avg', sentence_1_avg_vector[:10])

    return sen1_sen2_similarity


def compare_two_list_skills_sum(skills_1, skills_2):
    sentence_1_avg_vector = sum_feature_vector(skills_1.split(), model1=model1, num_features=300)
    sentence_2_avg_vector = sum_feature_vector(skills_2.split(), model1=model1, num_features=300)
    sen1_sen2_similarity = 1 - spatial.distance.cosine(sentence_1_avg_vector, sentence_2_avg_vector)

    # print ('Sum', sentence_1_avg_vector[:10])

    return sen1_sen2_similarity


def compare(cv, jd):
    cv = cv.replace(",", " ")
    jd = jd.replace(",", " ")

    result = compare_two_list_skills(cv, jd)
    if result == 1 and len(cv) < len(jd):
        result = len(cv.split()) / len(jd.split())
    return result


print(compare(sys.argv[1], sys.argv[2]))
# print(compare(["c++", "java", "ios"], ["spark", "mysql", "networking"]))
# model1.wv.vocab ## for extrcting the vocabulary of the .bin file (returns a dictionary)
